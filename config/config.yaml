models:
  text_encoder: "intfloat/e5-mistral-7b-instruct"  # Options: "intfloat/e5-mistral-7b-instruct" (4096 dim) or "Qwen/Qwen3-Embedding-0.6B" (1024 dim)
  text_encoder_type: "e5"  # "e5" or "qwen3" - auto-detected if not specified
  speech_encoder: "facebook/hubert-large-ls960-ft"
  generator: "Qwen/Qwen-Audio-Chat"  # Qwen-Audio-Chat for response generation
  
training:
  batch_size: 16
  learning_rate: 1e-4
  num_epochs: 10
  optimizer: "adamw"
  loss_type: "mse"  # ou "cosine"
  weight_decay: 0.01
  warmup_steps: 1000
  save_steps: 1000
  eval_steps: 500
  logging_steps: 100
  
generation:
  model_name: "Qwen/Qwen-Audio-Chat"  # Qwen-Audio-Chat model
  temperature: 0.7  # Sampling temperature
  max_new_tokens: 512  # Maximum tokens to generate
  top_p: 0.9  # Nucleus sampling parameter
  top_k_audio: 3  # Number of top audio passages to use for generation
  do_sample: true  # Whether to use sampling
  device: null  # Auto-detect if null (cuda/cpu)
  
data:
  dataset_name: "spoken_squad_test"  # Spoken Squad dataset
  dataset_config: null  # Não necessário para Spoken Squad
  audio_column: "audio"
  text_column: "passage_text"  # ou "context" dependendo da estrutura
  sample_rate: 16000
  max_audio_length: 60  # Spoken Squad pode ter passagens mais longas
  
paths:
  checkpoint_dir: "checkpoints/"
  data_dir: "data/"
  output_dir: "outputs/"

