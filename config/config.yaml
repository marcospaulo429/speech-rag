models:
  text_encoder: "Qwen/Qwen3-Embedding-0.6B"  # Options: "intfloat/e5-mistral-7b-instruct" (4096 dim) or "Qwen/Qwen3-Embedding-0.6B" (1024 dim)
  text_encoder_type: "e5"  # "e5" or "qwen3" - auto-detected if not specified
  speech_encoder: "facebook/hubert-large-ls960-ft"
  generator: "Qwen/Qwen-Audio-Chat"  # Qwen-Audio-Chat for response generation
  
training:
  batch_size: 16
  learning_rate: 1e-4
  num_epochs: 10
  optimizer: "adamw"
  loss_type: "cosine"  # ou "mse"
  weight_decay: 0.01
  warmup_steps: 1000
  save_steps: 1000
  eval_steps: 500
  logging_steps: 100
  
generation:
  model_name: "Qwen/Qwen-Audio-Chat"  # Qwen-Audio-Chat model
  temperature: 0.7  # Sampling temperature
  max_new_tokens: 512  # Maximum tokens to generate
  top_p: 0.9  # Nucleus sampling parameter
  top_k_audio: 3  # Number of top audio passages to use for generation
  do_sample: true  # Whether to use sampling
  device: null  # Auto-detect if null (cuda/cpu)
  
data:
  dataset_name: "SpokenSQuAD"
  sample_rate: 16000
  max_audio_length: 60.0
  
paths:
  # Use absolute path to be safe
  data_dir: "/Users/orlow/dev/paper-audio/speech-rag/data"
  output_dir: "/Users/orlow/dev/paper-audio/speech-rag/outputs/"

